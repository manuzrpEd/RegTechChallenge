{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ecfe16",
   "metadata": {},
   "source": [
    "# RegTech Challenge\n",
    "\n",
    "This notebook reads Reverse Repo json file data, downloads the Investment Firm Regulation and implements\n",
    "a calculator in Python.\n",
    "\n",
    "The task is to get a rough understanding of the objectives of the Investment Firm Regulation and implement\n",
    "a calculator in Python.\n",
    "\n",
    "For the purpose of this exercise, we will limit the implementation to the Trading Counterparty Default Risk\n",
    "(K-TCD) for a Reverse Repo transaction.\n",
    "\n",
    "It is not necessary any resource other than the definitions in Chapter 4 Section 1 \"Trading Counterparty default\" in the\n",
    "Investment Firm Regulation (Articles 26 to 32). <a href=\"https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32019R2033\">IFR link.</a>\n",
    "\n",
    "The code should accept as an input the two legs of the SFT as a JSON file (.json) that conforms to the\n",
    "securities.json schema of the FIRE Data Format and return the K-TCD for that transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e291cc",
   "metadata": {},
   "source": [
    "If you have already installed these libraries, comment these lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "164d93a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.20.3)\n",
      "Requirement already satisfied: pdfplumber in c:\\programdata\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: pdfminer.six==20211012 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfplumber) (20211012)\n",
      "Requirement already satisfied: Pillow>=8.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfplumber) (8.4.0)\n",
      "Requirement already satisfied: Wand>=0.6.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfplumber) (0.6.7)\n",
      "Requirement already satisfied: chardet in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer.six==20211012->pdfplumber) (4.0.0)\n",
      "Requirement already satisfied: cryptography in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer.six==20211012->pdfplumber) (3.4.8)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography->pdfminer.six==20211012->pdfplumber) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography->pdfminer.six==20211012->pdfplumber) (2.20)\n"
     ]
    }
   ],
   "source": [
    "# If you have already installed these libraries, comment these lines:\n",
    "!pip install numpy\n",
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deea13c",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d42fd7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os, json\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aefd823",
   "metadata": {},
   "source": [
    "define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "852ad816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "def download_file(download_url, filename):\n",
    "    \"\"\"\n",
    "    Download PDF from url and save in current directory\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = urllib.request.urlopen(download_url)    \n",
    "        file = open(filename + \".pdf\", 'wb')\n",
    "        file.write(response.read())\n",
    "        file.close()\n",
    "        print(\"\\n PDF downloaded from url\")\n",
    "        return response.status\n",
    "    except:\n",
    "        print(\"\\n Error while downloading the PDF from url\")\n",
    "        return response.status\n",
    "        pass\n",
    "\n",
    "def extract_text_fromPDFReader(pdf):\n",
    "    '''\n",
    "    this function returns the text from the pdf\n",
    "    '''\n",
    "    txt = []\n",
    "    for i in range(len(pdf.pages)):\n",
    "        \n",
    "        # creating a page object\n",
    "        pageObj = pdf.pages[i]\n",
    "     \n",
    "        # extracting text from page\n",
    "        txt.append(pageObj.extract_text())\n",
    "    return txt\n",
    "\n",
    "def extract_text_fromPDFReader_headerless(pdf):\n",
    "    '''\n",
    "    this function returns the text from the pdf removing the header contained in the first line\n",
    "    '''\n",
    "    txt_headerless = []\n",
    "    for i in range (len(pdf.pages)):\n",
    "        \n",
    "        # creating a page object\n",
    "        pageObj = pdf.pages[i]\n",
    "        \n",
    "        tx = pageObj.extract_text()\n",
    "        tx = tx.split('\\n')\n",
    "        tx = tx[1:]\n",
    "        tx = '\\n'.join(tx)\n",
    "        txt_headerless.append(tx)\n",
    "    return txt_headerless\n",
    "\n",
    "def get_dict_from_regulation(flat_headerless_text):\n",
    "    '''\n",
    "    This function returns a dictionary ordering the parts, titles, chapters, articles and points\n",
    "    from the regulation written in the PDF.\n",
    "    '''\n",
    "    # adjust Articles' syntax\n",
    "    for i in range(1,66):\n",
    "        flat_headerless_text=flat_headerless_text.replace('\\nArticle {} \\n'.format(i),'\\nArticle-{} \\n'.format(i))\n",
    "        \n",
    "    # adjust Points' syntax\n",
    "    for i in range(1,20):\n",
    "        flat_headerless_text=flat_headerless_text.replace('\\n{}. '.format(i),'\\n-{}. '.format(i))\n",
    "\n",
    "    # Parts\n",
    "    parts = flat_headerless_text.split(\" \\nPART \")\n",
    "    parts = { i : parts[i] for i in range(0, len(parts) ) }\n",
    "    for i in parts.keys():\n",
    "        parts[i]={ 'text' : parts[i]}\n",
    "\n",
    "    # Titles\n",
    "    for i in parts.keys():\n",
    "        if ' \\nTITLE ' in parts[i]['text']:\n",
    "            parts[i]['titles'] = { j : parts[i]['text'].split(\" \\nTITLE \")[j] for j in range(0, len(parts[i]['text'].split(\" \\nTITLE \")) ) }\n",
    "        else:\n",
    "            parts[i]['titles'] = {}\n",
    "    for i in parts.keys():\n",
    "        for j in parts[i]['titles'].keys():\n",
    "            parts[i]['titles'][j]={ 'text' : parts[i]['titles'][j]}\n",
    "            \n",
    "    # Chapters\n",
    "    for i in parts.keys():\n",
    "        if len(parts[i]['titles'])>0:\n",
    "            for k in parts[i]['titles'].keys():\n",
    "                if ' \\nCHAPTER ' in parts[i]['titles'][k]['text']:\n",
    "                    parts[i]['titles'][k]['chapters'] = { j : parts[i]['titles'][k]['text'].split(\" \\nCHAPTER \")[j] for j in range(0, len(parts[i]['titles'][k]['text'].split(\" \\nCHAPTER \")) ) }\n",
    "                else:\n",
    "                    parts[i]['titles'][k]['chapters'] = {}\n",
    "        else:\n",
    "            parts[i]['titles']['chapters'] = {} \n",
    "    for i in parts.keys():\n",
    "        for j in parts[i]['titles'].keys():\n",
    "            if (len(parts[i]['titles']) > 0) and (len(parts[i]['titles'].keys()) > 1):\n",
    "                for k in parts[i]['titles'][j]['chapters'].keys():\n",
    "                    parts[i]['titles'][j]['chapters'][k]={ 'text' : parts[i]['titles'][j]['chapters'][k]}\n",
    "                    \n",
    "    # Articles\n",
    "    for i in parts.keys():\n",
    "        # if part but no titles\n",
    "        if len(parts[i]['titles']) < 2:\n",
    "            lst = { j : parts[i]['text'].split(\" \\nArticle-\")[j] for j in range(0, len(parts[i]['text'].split(\" \\nArticle-\")) ) }\n",
    "            \n",
    "            if len(lst)>1:\n",
    "                parts[i]['titles']['articles'] = lst\n",
    "            else:\n",
    "                parts[i]['titles']['articles'] = {}\n",
    "\n",
    "        else:\n",
    "            for k in parts[i]['titles'].keys():\n",
    "                # if part and titles but no chapters        \n",
    "                if parts[i]['titles'][k]['chapters'] == {}:\n",
    "                    lst = { j : parts[i]['titles'][k]['text'].split(\" \\nArticle-\")[j] for j in range(0, len(parts[i]['titles'][k]['text'].split(\" \\nArticle-\")) ) }\n",
    "                    \n",
    "                    if len(lst)>1:\n",
    "                        parts[i]['titles'][k]['articles'] = lst\n",
    "                    else:\n",
    "                        parts[i]['titles'][k]['articles'] = {}\n",
    "                else:\n",
    "                    # if part and titles and chapters \n",
    "                    for l in parts[i]['titles'][k]['chapters'].keys():\n",
    "                        lst = { j : parts[i]['titles'][k]['chapters'][l]['text'].split(\" \\nArticle-\")[j] for j in range(0, len(parts[i]['titles'][k]['chapters'][l]['text'].split(\" \\nArticle-\")) ) }\n",
    "                        \n",
    "                        if len(lst)>1:\n",
    "                            parts[i]['titles'][k]['chapters'][l]['articles'] = lst\n",
    "                        else:\n",
    "                            parts[i]['titles'][k]['chapters'][l]['articles'] = {}\n",
    "    for i in parts.keys():\n",
    "        if ('articles' in parts[i]['titles'].keys()) and (parts[i]['titles']['articles'] != {}):\n",
    "            for k in parts[i]['titles']['articles'].keys():\n",
    "                parts[i]['titles']['articles'][k]={ 'text' : parts[i]['titles']['articles'][k]}\n",
    "        else:\n",
    "            for j in parts[i]['titles'].keys():\n",
    "                if ('articles' not in parts[i]['titles'].keys()) and ('articles' in parts[i]['titles'][j]) and (parts[i]['titles'][j]['articles'] != {}):\n",
    "                    for k in parts[i]['titles'][j]['articles'].keys():\n",
    "                        parts[i]['titles'][j]['articles'][k]={ 'text' : parts[i]['titles'][j]['articles'][k]}\n",
    "                elif ('articles' not in parts[i]['titles'].keys()) and ('articles' not in parts[i]['titles'][j]) and (parts[i]['titles'][j]['chapters'] != {}):\n",
    "                    for k in parts[i]['titles'][j]['chapters'].keys():\n",
    "                        if parts[i]['titles'][j]['chapters'][k]['articles'] != {}:\n",
    "                            for l in parts[i]['titles'][j]['chapters'][k]['articles'].keys():\n",
    "                                parts[i]['titles'][j]['chapters'][k]['articles'][l]={ 'text' : parts[i]['titles'][j]['chapters'][k]['articles'][l]}\n",
    "                         \n",
    "    # Points\n",
    "    for i in parts.keys():\n",
    "        # if part but no titles\n",
    "        if ('articles' in parts[i]['titles'].keys()) and (parts[i]['titles']['articles'] == {}):\n",
    "            parts[i]['titles']['points'] = {}\n",
    "        elif ('articles' in parts[i]['titles'].keys()) and (parts[i]['titles']['articles'] != {}):\n",
    "            for a in parts[i]['titles']['articles']:\n",
    "                lst = { j : parts[i]['titles']['articles'][a]['text'].split(\" \\n-\")[j] for j in range(0, len(parts[i]['titles']['articles'][a]['text'].split(\" \\n-\")) ) }\n",
    "                \n",
    "                if len(lst)>1:\n",
    "                    parts[i]['titles']['articles'][a] = lst\n",
    "                else:\n",
    "                    parts[i]['titles']['articles'][a] = {}\n",
    "        \n",
    "        else:\n",
    "            for k in parts[i]['titles'].keys():\n",
    "                # if part and titles but no chapters        \n",
    "                if parts[i]['titles'][k]['chapters'] == {}:\n",
    "                    if parts[i]['titles'][k]['articles'] == {}:\n",
    "                        parts[i]['titles'][k]['points'] = {} \n",
    "                    else:\n",
    "                        for a in parts[i]['titles'][k]['articles']:\n",
    "                            lst = { j : parts[i]['titles'][k]['articles'][a]['text'].split(\" \\n-\")[j] for j in range(0, len(parts[i]['titles'][k]['articles'][a]['text'].split(\" \\n-\")) ) }\n",
    "                            \n",
    "                            if len(lst)>1:\n",
    "                                parts[i]['titles'][k]['articles'][a]['points'] = lst\n",
    "                            else:\n",
    "                                parts[i]['titles'][k]['articles'][a]['points'] = {}\n",
    "                else:\n",
    "                    # if part and titles and chapters \n",
    "                    for l in parts[i]['titles'][k]['chapters'].keys():\n",
    "                        if parts[i]['titles'][k]['chapters'][l]['articles'] == {}:\n",
    "                            parts[i]['titles'][k]['chapters'][l]['points'] = {} \n",
    "                        else:\n",
    "                            for a in parts[i]['titles'][k]['chapters'][l]['articles']:\n",
    "                                lst = { j : parts[i]['titles'][k]['chapters'][l]['articles'][a]['text'].split(\" \\n-\")[j] for j in range(0, len(parts[i]['titles'][k]['chapters'][l]['articles'][a]['text'].split(\" \\n-\")) ) }\n",
    "                            \n",
    "                                if len(lst)>1:\n",
    "                                    parts[i]['titles'][k]['chapters'][l]['articles'][a]['points'] = lst\n",
    "                                else:\n",
    "                                    parts[i]['titles'][k]['chapters'][l]['articles'][a]['points'] = {}\n",
    "    \n",
    "    return parts\n",
    "\n",
    "def get_risk_factor(issuer_type,rf1,rf2,rf3):\n",
    "    if issuer_type in rf1 or issuer_type in rf2:\n",
    "        rf=0.016\n",
    "    elif issuer_type in rf3:\n",
    "        rf=0.08\n",
    "    else:\n",
    "        rf=np.nan\n",
    "        print(\"\\n Issuer type not found\")\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b4ede8",
   "metadata": {},
   "source": [
    "<li> 0. Parameters </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc5239ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regulatory documentation, pdf path\n",
    "pdf_path = \"https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32019R2033\"\n",
    "pdf_name = \"Regulation\"\n",
    "pdf_name_backup = \"CELEX_32019R2033_EN_TXT\"\n",
    "rf1=['central_bank','central_govt']\n",
    "rf2=['investment_firm','credit_institution']\n",
    "rf3=['other','other_financial']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df8641e",
   "metadata": {},
   "source": [
    "<li>1. Read json data</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12781a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'rev_repo_cash_leg',\n",
       "  'date': '2021-06-01T00:00:00Z',\n",
       "  'currency_code': 'GBP',\n",
       "  'end_date': '2021-07-01T00:00:00Z',\n",
       "  'balance': -1500,\n",
       "  'movement': 'cash',\n",
       "  'sft_type': 'rev_repo',\n",
       "  'start_date': '2021-06-01T00:00:00Z',\n",
       "  'type': 'cash',\n",
       "  'trade_date': '2021-07-01T00:00:00Z',\n",
       "  'customer': {'type': 'regional_govt'}},\n",
       " {'id': 'rev_repo_asset_leg',\n",
       "  'date': '2021-06-01T00:00:00Z',\n",
       "  'currency_code': 'GBP',\n",
       "  'end_date': '2021-07-01T00:00:00Z',\n",
       "  'mtm_dirty': 1400,\n",
       "  'movement': 'asset',\n",
       "  'sft_type': 'rev_repo',\n",
       "  'start_date': '2021-06-01T00:00:00Z',\n",
       "  'type': 'bond',\n",
       "  'trade_date': '2021-07-01T00:00:00Z',\n",
       "  'customer': {'type': 'regional_govt'},\n",
       "  'issuer': {'type': 'central_govt'}}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directory pointing to the directory where to read the json file\n",
    "path_to_json = os.getcwd()\n",
    "\n",
    "# name of the json file with the data\n",
    "data_json = 'data.json'\n",
    "\n",
    "f=open(path_to_json + \"\\\\\" + data_json)\n",
    "\n",
    "jl=json.load(f)\n",
    "\n",
    "for i in range(len(jl['data'])):\n",
    "    jl[jl['data'][i]['movement']]=jl['data'][i]\n",
    "\n",
    "jl.pop('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b04a17",
   "metadata": {},
   "source": [
    "<li>2. Download Regulation file</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f81f9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " PDF downloaded from url\n"
     ]
    }
   ],
   "source": [
    "resp=download_file(pdf_path, pdf_name)\n",
    "    \n",
    "# creating an object \n",
    "if resp == 200:\n",
    "    file = open(pdf_name + \".pdf\", 'rb')\n",
    "else:\n",
    "    file = open(pdf_name_backup + \".pdf\", 'rb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a179d14",
   "metadata": {},
   "source": [
    "<li>3. Read (extract) text from PDF</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60a2d435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " number of pages in pdf file:  63\n"
     ]
    }
   ],
   "source": [
    "# creating a pdf reader object\n",
    "pdf = pdfplumber.open(file)\n",
    "\n",
    "# printing number of pages in pdf file\n",
    "print(\"\\n number of pages in pdf file: \",len(pdf.pages))\n",
    "\n",
    "#extract all text\n",
    "txt=extract_text_fromPDFReader(pdf)\n",
    "\n",
    "#remove header of each page to keep only text\n",
    "txt_headerless=extract_text_fromPDFReader_headerless(pdf)\n",
    "\n",
    "flat_headerless_text='\\n'.join(txt_headerless)   \n",
    "\n",
    "# dictionary of the regulation\n",
    "d = get_dict_from_regulation(flat_headerless_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86107b48",
   "metadata": {},
   "source": [
    "<li>4. Calculating K-TCD</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c82e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Own Funds Requirement for  data.json  is  2.11 GBP\n",
      "\n",
      " End\n"
     ]
    }
   ],
   "source": [
    "# Article 26        \n",
    "alpha=1.2\n",
    "\n",
    "# Table 2, risk factor\n",
    "rf = get_risk_factor(jl['asset']['issuer']['type'], rf1, rf2, rf3)\n",
    "\n",
    "# Article 27, replacement cost\n",
    "rc = -jl['cash']['balance']\n",
    "# potential future exposure\n",
    "pfe = 0\n",
    "\n",
    "# Article 30\n",
    "adjustment = 0.00707\n",
    "C = (1-adjustment)*jl['asset']['mtm_dirty']\n",
    "\n",
    "# Article 27, exposure value\n",
    "EV = max(0,rc+pfe-C)\n",
    "\n",
    "#Article 32, Credit valuation adjustment\n",
    "cva = 1\n",
    "\n",
    "# Article 26, Own funds requirement\n",
    "\n",
    "own_funds_requirement = alpha*EV*rf*cva\n",
    "\n",
    "print(\"\\n Own Funds Requirement for \",data_json,\" is \",round(own_funds_requirement,2),jl['asset']['currency_code'])\n",
    "print (\"\\n End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
